{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "234e1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61443d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "034e56e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus - A large collection of text\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d26b693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e073ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(brown.categories())\n",
    "print(len(brown.categories()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10401f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Dan', 'Morgan', 'told', 'himself', 'he', 'would', 'forget', 'Ann', 'Turner', '.'], ['He', 'was', 'well', 'rid', 'of', 'her', '.'], ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = brown.sents(categories = 'adventure')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1109aad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4637"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a7f65c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dan Morgan told himself he would forget Ann Turner .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbd52e3",
   "metadata": {},
   "source": [
    "# Bag of Words Pipeline\n",
    "- Get the Data/Corpus\n",
    "- Tokenisation, Stopword Removal\n",
    "- Stemming\n",
    "- Building a Vocab\n",
    "- Vectorization\n",
    "- Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b6816",
   "metadata": {},
   "source": [
    "### Tokenisation, Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bbf861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"It was a very pleasant day. The weather was cool and there were light showers.\n",
    "I went to the market to buy some fruits.\"\"\"\n",
    "\n",
    "sentence = \"Send all the 50 documents related to chapters 1,2,3 at prateek@cb.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2311c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17de61d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It was a very pleasant day.', 'The weather was cool and there were light showers.', 'I went to the market to buy some fruits.']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "sents = sent_tokenize(document)\n",
    "print(sents)\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ef9fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8421e1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Send', 'all', 'the', '50', 'documents', 'related', 'to', 'chapters', '1,2,3', 'at', 'prateek', '@', 'cb.com']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(words)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9d14b",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bbba335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b570f150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'should', 'shan', \"weren't\", 'no', 'mightn', 'this', 'over', 'how', 'won', 'any', 'before', 'had', \"won't\", 'against', 'into', 'off', 'after', 'both', 'has', 'them', 'your', 'but', 'with', \"mustn't\", 'not', \"doesn't\", 'nor', 'do', 'ours', 'which', 'll', \"you're\", 'himself', 're', \"needn't\", \"wouldn't\", 'herself', 'a', 'will', \"you'll\", 'during', 'myself', 'below', 'on', 'for', 'some', 'theirs', 'y', 'at', 'ma', 'we', 'in', 'out', 'these', 'it', 'themselves', 'further', 'd', 's', 'very', 'above', 'that', 'are', 'ourselves', 'm', 'he', 'to', 'having', 'between', \"she's\", 'hers', 'have', 't', 'same', \"couldn't\", 'again', 'and', 'their', \"don't\", 'where', 'me', 'than', 'isn', 'needn', 'down', \"didn't\", 'him', 'what', \"hasn't\", 'from', 'other', 'you', 'doesn', 'up', 'ain', 'yourselves', 'weren', 'most', 'why', \"aren't\", 'about', \"shouldn't\", \"you've\", 'they', 'own', 'when', 'those', 'her', 'while', 've', 'because', 'under', 'now', 'don', 'such', 'wouldn', 'few', 'too', 'was', \"mightn't\", 'wasn', 'being', 'or', 'she', 'through', 'hasn', 'been', 'didn', 'is', \"wasn't\", \"isn't\", \"it's\", 'i', 'our', 'yours', \"that'll\", 'yourself', 'then', 'of', 'an', 'just', 'who', 'here', \"should've\", 'couldn', 'doing', 'if', 'by', 'whom', 'were', 'his', 'once', 'more', 'the', 'aren', 'o', 'am', 'hadn', \"shan't\", 'so', 'shouldn', \"haven't\", 'all', 'itself', 'my', 'each', 'be', 'can', 'does', 'its', 'haven', 'there', \"hadn't\", 'did', 'only', 'mustn', 'as', 'until', \"you'd\"}\n"
     ]
    }
   ],
   "source": [
    "print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23018757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text,stopwords):\n",
    "    useful_words = [w for w in text if w not in stopwords]\n",
    "    return useful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1ec09bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'bothered', 'much']\n"
     ]
    }
   ],
   "source": [
    "text = \"I am not bothered about her very much\".split()\n",
    "useful_text = remove_stopwords(text,sw)\n",
    "print(useful_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7d9b6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'I' in sw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59290bcd",
   "metadata": {},
   "source": [
    "### Tokenization using Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eb55045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f8387ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('[a-zA-Z@.]+')\n",
    "useful_text_ = tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ade10b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Send',\n",
       " 'all',\n",
       " 'the',\n",
       " 'documents',\n",
       " 'related',\n",
       " 'to',\n",
       " 'chapters',\n",
       " 'at',\n",
       " 'prateek@cb.com']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_text_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad632384",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "- Process that transforms particular words (verbs, plurals) into their radical form\n",
    "- Preserve the semantics of the sentence without increasing the number of unique tokens\n",
    "- Example : jumps, jumping, jumped, jump ==> jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdb655d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"\"\"Foxes love to make jumps.The quick brown fox was seen jumping over the\n",
    "        lovely dog from a 6ft high wall\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2b664d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer,PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a156b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ba3d8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('jumping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee2ffd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('lovely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e8d46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowball Stemmer\n",
    "ss = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8a6ab11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.stem('lovely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0468d988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f6fd09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jumping'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn = WordNetLemmatizer()\n",
    "wn.lemmatize('jumping')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd996014",
   "metadata": {},
   "source": [
    "### Building a Vocab & Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ea811df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Corpus - Contains 4 documents, each document can have 1 or more sentence\n",
    "corpus = [\n",
    "    'Indian cricket team will win World Cup, says Capt. Virat Kohli. World cup will be held at Sri Lanka.',\n",
    "    'We will win the next Lok Sabha elections, says confident Indian PM.',\n",
    "    'The nobel laurate won the hearts of the people.',\n",
    "    'The movie Raazi is an exciting Indian Spy thriller based upon a real story.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c9cda01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "189a8c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78a4c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_corpus = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61dc080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_corpus = vectorized_corpus.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccd3585c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 1, 2, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 2, 1, 0, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef3c31cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indian': 12, 'cricket': 6, 'team': 31, 'will': 37, 'win': 38, 'world': 40, 'cup': 7, 'says': 27, 'capt': 4, 'virat': 35, 'kohli': 14, 'be': 3, 'held': 11, 'at': 1, 'sri': 29, 'lanka': 15, 'we': 36, 'the': 32, 'next': 19, 'lok': 17, 'sabha': 26, 'elections': 8, 'confident': 5, 'pm': 23, 'nobel': 20, 'laurate': 16, 'won': 39, 'hearts': 10, 'of': 21, 'people': 22, 'movie': 18, 'raazi': 24, 'is': 13, 'an': 0, 'exciting': 9, 'spy': 28, 'thriller': 33, 'based': 2, 'upon': 34, 'real': 25, 'story': 30}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "639f7015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorized_corpus[0]))\n",
    "print(len(cv.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9da85a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reverse Mapping\n",
    "numbers = vectorized_corpus[2]\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "025a572a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['hearts', 'laurate', 'nobel', 'of', 'people', 'the', 'won'],\n",
       "       dtype='<U9')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.inverse_transform(numbers.reshape((1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36dae50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbbc4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7777b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad304334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e3317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284026e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d1f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b7059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d169a2ad",
   "metadata": {},
   "source": [
    "### More Ways to Create Features\n",
    "- Unigram - every word as a feature\n",
    "- Bigrams\n",
    "- Trigrams\n",
    "- n-grams\n",
    "- TF-IDF Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f7816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
